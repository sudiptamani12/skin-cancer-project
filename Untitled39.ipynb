{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPYBti6h1MtJ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Unzip Dataset (ensure path is correct)\n",
        "!unzip \"/content/gdrive/MyDrive/SkinCancer/Dataset.zip\" > /dev/null\n",
        "\n",
        "# Load dataset from the unzipped folder (replace with actual dataset paths)\n",
        "def load_images(image_folder, target_size=(224, 224)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {'benign': 0, 'malignant': 1, 'precancerous': 2}  # Update according to your labels\n",
        "    for label in label_map:\n",
        "        folder_path = os.path.join(image_folder, label)\n",
        "        for img_name in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, target_size)\n",
        "            img = img / 255.0  # Normalize\n",
        "            images.append(img)\n",
        "            labels.append(label_map[label])\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Count number of images in Train and Test directories\n",
        "def count_images(image_folder):\n",
        "    count = {}\n",
        "    for label in os.listdir(image_folder):\n",
        "        label_folder = os.path.join(image_folder, label)\n",
        "        count[label] = len(os.listdir(label_folder))\n",
        "    return count\n",
        "\n",
        "# Define directories for your dataset\n",
        "train_image_folder = \"/content/gdrive/MyDrive/SkinCancer/Dataset/train\"\n",
        "test_image_folder = \"/content/gdrive/MyDrive/SkinCancer/Dataset/test\"\n",
        "\n",
        "# Load dataset\n",
        "train_images, train_labels = load_images(train_image_folder)\n",
        "test_images, test_labels = load_images(test_image_folder)\n",
        "\n",
        "# Count the number of images in train and test directories\n",
        "train_counts = count_images(train_image_folder)\n",
        "test_counts = count_images(test_image_folder)\n",
        "\n",
        "print(f\"Training data class distribution: {train_counts}\")\n",
        "print(f\"Testing data class distribution: {test_counts}\")\n",
        "\n",
        "# Data Visualization: Distribution of classes in the training dataset\n",
        "def plot_class_distribution(counts, title='Class Distribution'):\n",
        "    labels = list(counts.keys())\n",
        "    values = list(counts.values())\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(labels, values, color='skyblue')\n",
        "    plt.xlabel('Classes')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize class distribution in the training dataset\n",
        "plot_class_distribution(train_counts, 'Training Dataset Class Distribution')\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Building: CNN + ViT + XGBoost Hybrid Model\n",
        "def create_cnn_vit_model(input_shape=(224, 224, 3)):\n",
        "    # CNN component\n",
        "    cnn_input = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu')(cnn_input)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    # ViT component (Vision Transformer)\n",
        "    vit_input = layers.Input(shape=input_shape)\n",
        "    vit_x = layers.Reshape((-1, 224))(vit_input)  # Reshape for ViT input\n",
        "    vit_x = layers.MultiHeadAttention(num_heads=4, key_dim=64)(vit_x, vit_x)\n",
        "    vit_x = layers.GlobalAveragePooling1D()(vit_x)\n",
        "\n",
        "    # Merging CNN and ViT\n",
        "    combined = layers.concatenate([x, vit_x])\n",
        "\n",
        "    # Final Classification Layer\n",
        "    output = layers.Dense(3, activation='softmax')(combined)\n",
        "\n",
        "    model = models.Model(inputs=[cnn_input, vit_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "cnn_vit_model = create_cnn_vit_model()\n",
        "\n",
        "# Model Architecture summary\n",
        "cnn_vit_model.summary()\n",
        "\n",
        "# Training: Measure elapsed time\n",
        "start_time = time.time()\n",
        "\n",
        "history = cnn_vit_model.fit(\n",
        "    [X_train, X_train], y_train,  # Using the same X_train for both inputs (CNN and ViT)\n",
        "    validation_data=([X_val, X_val], y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"Training time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Plotting Training and Validation Accuracy & Loss\n",
        "def plot_accuracy_loss(history):\n",
        "    # Accuracy Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize accuracy and loss curves\n",
        "plot_accuracy_loss(history)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = cnn_vit_model.evaluate([test_images, test_images], test_labels)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate Confusion Matrix\n",
        "y_pred = np.argmax(cnn_vit_model.predict([test_images, test_images]), axis=1)\n",
        "conf_matrix = confusion_matrix(test_labels, y_pred)\n",
        "\n",
        "# Display Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant', 'Precancerous'], yticklabels=['Benign', 'Malignant', 'Precancerous'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(classification_report(test_labels, y_pred, target_names=['Benign', 'Malignant', 'Precancerous']))\n",
        "\n",
        "# XGBoost for post-processing (optional)\n",
        "xgboost_model = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=3)\n",
        "xgboost_model.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "y_pred_xgb = xgboost_model.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "# Evaluate XGBoost Model\n",
        "print(f\"XGBoost Accuracy: {accuracy_score(test_labels, y_pred_xgb)}\")\n"
      ]
    }
  ]
}